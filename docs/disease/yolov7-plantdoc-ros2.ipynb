{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy disease detection model to ROS2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, we trained and evaluated YOLOv7 model on the PlantDoc dataset. Next, we will deploy the trained disease detection model to Robot Operating System 2 (ROS2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So What is ROS2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robot Operating System (ROS) is a set of open-source software libraries and tools for building robotic systems. It provides a common framework for creating, programming, and deploying robotic systems in various domains, including industrial, research, and personal use.\n",
    "\n",
    "ROS2 is the second major version of ROS. It was designed to address some of the limitations of the original ROS and to improve performance, scalability, and security. Some of the main features of ROS2 include:\n",
    "\n",
    "- Real-time support: ROS2 supports real-time computing with the use of the DDS (Data Distribution Service) middleware, which allows for low-latency communication between ROS2 nodes.\n",
    "- Improved scalability: ROS2 allows for distributed systems, with multiple computers communicating over a network. This allows for better scalability and the ability to handle more complex robotic systems.\n",
    "- Better security: ROS2 uses DDS security features, such as authentication and encryption, to provide better security for robotic systems.\n",
    "- Improved support for multiple languages: ROS2 supports multiple languages, including C++, Python, and C#, which allow the developers to use the language they are most comfortable with.\n",
    "- Robustness: ROS2 improve robustness of the system, as well as resilience to communication failures and other unexpected events.\n",
    "\n",
    "There are several core concepts that are fundamental to understanding how ROS2 works:\n",
    "\n",
    "1. Nodes: In ROS2, nodes are the basic units of computation. A node represents a process that runs on a computer and communicates with other nodes. Nodes can be written in any programming language that is supported by ROS2, such as C++, Python, or C#. Each node can provide or consume one or more services or publish and subscribe to one or more topics.\n",
    "2. Topics: Topics are the means by which nodes can exchange messages. In ROS2, a topic is a named channel to which nodes can publish messages and to which other nodes can subscribe to receive messages. Topics are used to send sensor data, control commands, and other types of information between nodes.\n",
    "3. Services: Services provide a mechanism for nodes to request and receive a specific piece of information or to perform a specific action. Services are synchronous and request-response based, which means that a client node sends a request to a service and waits for a response. Services in ROS2 are defined by a pair of request and response message types.\n",
    "4. Actions: Actions are similar to services but are designed for more complex tasks with feedback and goal status. They can be used to control the execution of long-lasting tasks, such as navigation or grasping.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the trained disease detection YOLOv7 model to ROS2, we need take the following steps:\n",
    "\n",
    "- Install ROS2 and the required dependencies. \n",
    "- Write a ROS2 node to simulate a camera to capture the plant disease images, and use the ROS2 API to publish the images as messages on a ROS2 topic.\n",
    "- Write a ROS2 node to subscribe to the images topic and perform plant disease detection on the received images.\n",
    "\n",
    "## Write a node to publish images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from std_msgs.msg import String\n",
    "from cv_bridge import CvBridge\n",
    "from sensor_msgs.msg import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class MinimalPublisher(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('minimal_publisher')\n",
    "        self.publisher = self.create_publisher(Image, 'Image', 10)\n",
    "        timer_period = 0.02 # seconds\n",
    "        self.timer = self.create_timer(timer_period, self.timer_callback)\n",
    "\n",
    "        root_dir = \"PlantDoc-1/test/images/\"\n",
    "        self.img_paths = [\n",
    "            os.path.join(root_dir, img_name)\n",
    "            for img_name in os.listdir(root_dir)\n",
    "            ]\n",
    "        self.n_imgs = len(self.img_paths)\n",
    "\n",
    "        self.cv_image = cv2.imread(self.img_paths[0]) # the first image\n",
    "        self.i = 1\n",
    "        self.bridge = CvBridge()\n",
    "\n",
    "    def timer_callback(self):\n",
    "        self.publisher.publish(self.bridge.cv2_to_imgmsg(self.cv_image[:,:416]))\n",
    "        self.get_logger().info('Publishing an image')\n",
    "\n",
    "        height, width, channels = self.cv_image.shape\n",
    "        if width < 416 + 100: # concat the next image\n",
    "            next_cv_image = cv2.imread(self.img_paths[self.i])\n",
    "            self.cv_image = cv2.hconcat([self.cv_image, next_cv_image])\n",
    "            self.i += 1\n",
    "            if self.i == self.n_imgs:\n",
    "                self.i = 0\n",
    "        self.cv_image = self.cv_image[:, 1:]\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    minimal_publisher = MinimalPublisher()\n",
    "    rclpy.spin(minimal_publisher)\n",
    "    minimal_publisher.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the code above, it can mainly be broken down into 3 parts: initialization, timer callback, and starting the node.\n",
    "\n",
    "### Initialization\n",
    "In the initialization step, we declare a node called `minimal_publisher`. Next we create a basic publisher that utilize the `sensor_msgs.msg.Image` type to publish a topic name `Image` per `timer_period = 0.02` second. Next we prepare all the test images in `img_paths`. Then we also create a basic `CvBridge` tool to convert images from an OpenCV compatible type to a ROS2 `sensor_msgs.msg.Image` message type.\n",
    "\n",
    "### Timer callback\n",
    "Within the callback `timer_callback`, the images are converted to the ROS2 message type using `CvBridge` sequentially. We concatenate the images one by one.\n",
    "\n",
    "### Starting the node\n",
    "In the `main` function, the node is initialized and spined up to publish images.\n",
    "\n",
    "## Write a node to subscribe images and run plant disease detection on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from cv_bridge import CvBridge\n",
    "from sensor_msgs.msg import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import check_img_size, non_max_suppression, scale_coords, set_logging\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, time_synchronized, TracedModel\n",
    "\n",
    "\n",
    "class ImageSubscriber(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('image_subscriber')\n",
    "        self.subscription = self.create_subscription(Image, 'Image', self.listener_callback, 10)\n",
    "        self.subscription # prevent unused variable warning\n",
    "        self.bridge = CvBridge()\n",
    "\n",
    "        device = 'cuda:0'\n",
    "        set_logging()\n",
    "        device = select_device('0')\n",
    "        self.device = device\n",
    "        half = device.type != 'cpu'\n",
    "        self.half = half\n",
    "        weights = 'best.pt'\n",
    "        imgsz = 416\n",
    "        model = attempt_load(weights, map_location=device)\n",
    "        stride = int(model.stride.max())\n",
    "        imgsz = check_img_size(imgsz, s=stride)\n",
    "        model = TracedModel(model, device, img_size=imgsz)\n",
    "        model.half()\n",
    "        names = model.module.names if hasattr(model, 'module') else model.names\n",
    "        self.names = names\n",
    "        print(names)\n",
    "        colors = [[random.randint(0,255) for _ in range(3)] for _ in names]\n",
    "        self.colors = colors\n",
    "        if device.type != 'cpu':\n",
    "            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "        self.model = model\n",
    "\n",
    "        fourcc = cv2.VideoWriter.fourcc('m', 'p', '4', 'v')\n",
    "        self.out = cv2.VideoWriter('output.mp4', fourcc, 50, (416, 416))\n",
    "\n",
    "\n",
    "    def listener_callback(self, data):\n",
    "        self.get_logger().info('Receiving image')\n",
    "        img0 = self.bridge.imgmsg_to_cv2(data)\n",
    "        self.get_logger().info(str(img0.shape))\n",
    "        img = img0[:, :, ::-1].transpose(2, 0, 1)\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(self.device)\n",
    "        img = img.half() if self.half else img.float()\n",
    "        img /= 255.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(img, augment=False)[0]\n",
    "        conf_thres = 0.1\n",
    "        iou_thres = 0.45\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes=None, agnostic=False)\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            s = \"\"\n",
    "            gn = torch.tensor(img0.shape)[[1,0,1,0]]\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    label = f'{self.names[int(cls)]} {conf:.2f}'\n",
    "                    plot_one_box(xyxy, img0, label=label, color=self.colors[int(cls)], line_thickness=1)\n",
    "        # cv2.imshow(\"IMAGE\", img0)\n",
    "        # cv2.waitKey(1)\n",
    "        # cv2.destroyWindow(\"IMAGE\")\n",
    "        cv2.imwrite('received_test.jpg', img0)\n",
    "        self.out.write(img0)\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    image_subscriber = ImageSubscriber()\n",
    "    rclpy.spin(image_subscriber)\n",
    "    image_subscriber.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results are recorded as a short video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"393\" height=\"698\" src=\"https://www.youtube.com/embed/ty6OHxJW4tk\" title=\"Realtime plant disease detection using YOLOv7 and ROS2\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"393\" height=\"698\" src=\"https://www.youtube.com/embed/ty6OHxJW4tk\" title=\"Realtime plant disease detection using YOLOv7 and ROS2\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mkdocs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b49f19725d2c9b79544a913ef783648517ab69d5bcec7c7f412a70f1dbc8ab27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
